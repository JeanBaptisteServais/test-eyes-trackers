# _apply_from_Tuto-eyes-trackers



based on a pupil tracker, conda, dlib, cv2, model pre formed and tuto we try to detect the eye

<strong> 2 applications: First's </strong> pupil tracker (live), <strong>Second part</strong> of our eyes tracker (video register, cause distant serveur)

<strong>For example: </strong> put some animation on the face, alarm in case the conductor sleeps, eyes movement and duration on a web site, an experience of visual attention (you can consult it on the "super" web site: synergo).

Care you user need to be fix, no movement, eye visible, video frame resize for the application (explication bottom)

And care we need to register in part because we write for send 20 sec parts of video. CARE this is just a memo not a real explication.
could be improve with ml with points on the blanck picture


<strong> Tutorials : </strong>

TUTO 1

TUTO 2

TUTO 3

TUTO 4

TUTO 5

<strong> models : </strong>

model 1

model 2


<p align="center">

![ezgif com-video-to-gif](https://user-images.githubusercontent.com/54853371/75084619-8319a880-5521-11ea-8e70-ca8256b25d4f.gif)

<img width="300" heigh="300" src="https://user-images.githubusercontent.com/54853371/75084989-bad61f80-5524-11ea-90b0-1f5f36ef3392.gif">

</p>

![eyes_tracking1](https://user-images.githubusercontent.com/54853371/75084439-629d1e80-5520-11ea-8d3a-74f6ba269fd2.gif)
![eyes_tracking2](https://user-images.githubusercontent.com/54853371/75084440-63ce4b80-5520-11ea-8519-b6e6c347413d.gif)

eye tracker isn't precise and the user need to be fixe from the begening (the current gif isn't precise because i need glasses and i approch myself to the screen but it's my better face from all other video's i let u imagine !)
